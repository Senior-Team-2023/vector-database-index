{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Dict, List, Annotated\n",
    "import numpy as np\n",
    "import faiss\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pickle\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"0000_0.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "if filename.endswith(\".csv\"):\n",
    "    bucket_rec = []\n",
    "    with open(f\"./index/{filename}\", \"r\") as fin:\n",
    "        for row in fin.readlines():\n",
    "            row_splits = row.split(\",\")\n",
    "            # the first element is id\n",
    "            id = int(row_splits[0])\n",
    "            # the rest are embed\n",
    "            embed = [float(e) for e in row_splits[1:]]\n",
    "            embed = np.array(embed)\n",
    "            bucket_rec.append((id, embed))\n",
    "        # build the HNSW index\n",
    "        # bucket_rec = np.array(bucket_rec)\n",
    "        # self._HNSW_index(\n",
    "        #     data=bucket_rec,\n",
    "        #     m=128,\n",
    "        #     ef_construction=200,\n",
    "        #     ef_search=32,\n",
    "        #     filename=filename,\n",
    "        # )\n",
    "        # Knn using sklearn\n",
    "        knn = KNeighborsClassifier(n_neighbors=10, metric=\"cosine\")\n",
    "        knn.fit(\n",
    "            np.array([e[1] for e in bucket_rec]),\n",
    "            np.array([e[0] for e in bucket_rec]),\n",
    "        )\n",
    "        # save the index using pickle\n",
    "        with open(f\"./index/{filename}.index\", \"wb\") as fout:\n",
    "            pickle.dump(knn, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = np.array(\n",
    "    [\n",
    "        0.374540119,\n",
    "        0.950714306,\n",
    "        0.731993942,\n",
    "        0.598658484,\n",
    "        0.15601864,\n",
    "        0.15599452,\n",
    "        0.058083612,\n",
    "        0.866176146,\n",
    "        0.601115012,\n",
    "        0.708072578,\n",
    "        0.020584494,\n",
    "        0.969909852,\n",
    "        0.832442641,\n",
    "        0.212339111,\n",
    "        0.181824967,\n",
    "        0.18340451,\n",
    "        0.304242243,\n",
    "        0.524756432,\n",
    "        0.431945019,\n",
    "        0.29122914,\n",
    "        0.611852895,\n",
    "        0.139493861,\n",
    "        0.292144649,\n",
    "        0.366361843,\n",
    "        0.456069984,\n",
    "        0.785175961,\n",
    "        0.199673782,\n",
    "        0.514234438,\n",
    "        0.592414569,\n",
    "        0.046450413,\n",
    "        0.607544852,\n",
    "        0.170524124,\n",
    "        0.065051593,\n",
    "        0.948885537,\n",
    "        0.965632033,\n",
    "        0.808397348,\n",
    "        0.304613769,\n",
    "        0.097672114,\n",
    "        0.684233027,\n",
    "        0.440152494,\n",
    "        0.122038235,\n",
    "        0.49517691,\n",
    "        0.034388521,\n",
    "        0.909320402,\n",
    "        0.258779982,\n",
    "        0.662522284,\n",
    "        0.311711076,\n",
    "        0.520068021,\n",
    "        0.546710279,\n",
    "        0.184854456,\n",
    "        0.969584628,\n",
    "        0.775132823,\n",
    "        0.939498942,\n",
    "        0.89482735,\n",
    "        0.597899979,\n",
    "        0.921874235,\n",
    "        0.088492502,\n",
    "        0.195982862,\n",
    "        0.045227289,\n",
    "        0.325330331,\n",
    "        0.38867729,\n",
    "        0.271349032,\n",
    "        0.828737509,\n",
    "        0.356753327,\n",
    "        0.28093451,\n",
    "        0.542696083,\n",
    "        0.140924225,\n",
    "        0.802196981,\n",
    "        0.074550644,\n",
    "        0.986886937,\n",
    "    ]\n",
    ").reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distances [[0.17026952 0.17234684 0.17359812 0.18428113 0.18996226]]\n",
      "labels [[ 71  17 468 292 260]]\n",
      "Calculating score...\n",
      "[(0.17026951776473387, 71), (0.172346836401846, 17), (0.17359812140504816, 468), (0.1842811340688324, 292), (0.18996225809097111, 260)]\n"
     ]
    }
   ],
   "source": [
    "distances, labels = knn.kneighbors(query, n_neighbors=5)\n",
    "print(\"distances\", distances)\n",
    "print(\"labels\", labels)\n",
    "# calculate the score for each vector in the bucket\n",
    "print(\"Calculating score...\")\n",
    "scores = [(distances[0][i], labels[0][i]) for i in range(len(labels[0]))]\n",
    "scores = sorted(scores)[:5]\n",
    "# return the ids of the top_k records\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _HNSW_index( data, m, ef_construction, filename, ef_search):\n",
    "    index = faiss.IndexHNSWFlat(70, m)\n",
    "    # set efConstruction and efSearch parameters\n",
    "    index.hnsw.efConstruction = ef_construction\n",
    "    index.hnsw.efSearch = ef_search\n",
    "    # Wrap the index with IDMap\n",
    "    id_map = faiss.IndexIDMap(index)\n",
    "    id_map.add_with_ids(\n",
    "        np.array([e[1] for e in data]), np.array([e[0] for e in data])\n",
    "    )\n",
    "    # save the index\n",
    "    faiss.write_index(id_map, f\"./index/{filename}.index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_rec = []\n",
    "with open(f\"./index/{filename}\", \"r\") as fin:\n",
    "    for row in fin.readlines():\n",
    "        row_splits = row.split(\",\")\n",
    "        # the first element is id\n",
    "        id = int(row_splits[0])\n",
    "        # the rest are embed\n",
    "        embed = [float(e) for e in row_splits[1:]]\n",
    "        embed = np.array(embed)\n",
    "        bucket_rec.append((id, embed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bucket_rec = np.array(bucket_rec)\n",
    "_HNSW_index(\n",
    "    data=bucket_rec,\n",
    "    m=128,\n",
    "    ef_construction=200,\n",
    "    ef_search=32,\n",
    "    filename=filename,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_index = faiss.read_index(\n",
    "    f\"./index/{filename}.index\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distances [[8.17793   8.179846  8.186981  8.198956  8.254056  8.345868  8.506533\n",
      "  8.797141  8.8509865 8.917404 ]]\n",
      "labels [[ 950  392 1632  189 6904 4317 3127 9746 7999 7906]]\n",
      "Calculating score...\n",
      "[(8.17793, 950), (8.179846, 392), (8.186981, 1632), (8.198956, 189), (8.254056, 6904), (8.345868, 4317), (8.506533, 3127), (8.797141, 9746), (8.8509865, 7999), (8.917404, 7906)]\n"
     ]
    }
   ],
   "source": [
    "distances, labels = loaded_index.search(query, 10)\n",
    "print(\"distances\", distances)\n",
    "print(\"labels\", labels)\n",
    "# calculate the score for each vector in the bucket\n",
    "print(\"Calculating score...\")\n",
    "scores = [(distances[0][i], labels[0][i]) for i in range(len(labels[0]))]\n",
    "scores = sorted(scores)[:10]\n",
    "# return the ids of the top_k records\n",
    "print(scores)\n",
    "# return [s[1] for s in scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.cluster.vq import kmeans2\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_part = 16  # number of IVF partitions\n",
    "dataset = np.random.normal(size=(1000, 70))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(centroids, assignments) = kmeans2(dataset, num_part, iter=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 70)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.51168185,  0.18225576,  0.37021322, ..., -0.31593024,\n",
       "         0.11881143,  0.03136554],\n",
       "       [-0.28565728, -0.49904209, -0.0612307 , ..., -0.09203601,\n",
       "        -0.16423853, -0.05104231],\n",
       "       [-0.06713186,  0.46291873,  0.7767644 , ...,  0.02974499,\n",
       "        -0.9253968 , -0.16321818],\n",
       "       ...,\n",
       "       [-0.0770925 , -0.06430145, -0.41172783, ...,  0.09970878,\n",
       "         0.2766169 , -0.2589768 ],\n",
       "       [ 0.17554476,  0.2829007 ,  0.2984314 , ...,  0.01373098,\n",
       "         0.11269911, -0.25094596],\n",
       "       [ 0.21551573,  0.07543853, -0.57635857, ..., -0.15508406,\n",
       "        -0.01352909, -0.35860672]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroids #the choesen cetroids for the 16 partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(assignments) #assignment for each vector in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [np.argmin(np.linalg.norm(vec - centroids, axis=1)) for vec in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(test == assignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assignments[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [[] for _ in range(num_part)]\n",
    "for n, k in enumerate(assignments):\n",
    "    # n is the index of the vector\n",
    "    # k is the index of the cluster\n",
    "    index[k].append(n) # the nth vector gets added to the kth cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "71\n"
     ]
    }
   ],
   "source": [
    "query = np.random.normal(size=(70,))\n",
    "c = np.argmin(np.linalg.norm(centroids - query, axis=1))  # find the nearest partition\n",
    "print(c)\n",
    "nearest = np.argmin(np.linalg.norm(dataset[index[c]] - query, axis=1))  # find nearest neighbor\n",
    "print(nearest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.389149789375157\n"
     ]
    }
   ],
   "source": [
    "# print(dataset[nearest])  # the index of the nearest neighbor in the dataset\n",
    "# print(query)\n",
    "print(np.linalg.norm(dataset[nearest] - query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.IndexFlatL2(70)\n",
    "index.add(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "query = np.random.normal(size=(70,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "D, I = index.search(query.reshape(1, -1), k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[78.15851, 80.8537 , 85.08509, 85.5335 , 87.41831]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[973, 868, 993, 588, 879]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './index/index_peter.dta'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m  \n\u001b[1;32m----> 2\u001b[0m fp \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmemmap(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./index/index_peter.dta\u001b[39m\u001b[38;5;124m\"\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m71\u001b[39m))\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(fp)\n",
      "File \u001b[1;32mc:\\Users\\bemoi\\miniconda3\\envs\\faiss_env\\Lib\\site-packages\\numpy\\core\\memmap.py:229\u001b[0m, in \u001b[0;36mmemmap.__new__\u001b[1;34m(subtype, filename, dtype, mode, offset, shape, order)\u001b[0m\n\u001b[0;32m    227\u001b[0m     f_ctx \u001b[38;5;241m=\u001b[39m nullcontext(filename)\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 229\u001b[0m     f_ctx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(os_fspath(filename), (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m mode)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m f_ctx \u001b[38;5;28;01mas\u001b[39;00m fid:\n\u001b[0;32m    232\u001b[0m     fid\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './index/index_peter.dta'"
     ]
    }
   ],
   "source": [
    "import numpy as np  \n",
    "fp = np.memmap(\"./index/index_peter.dta\", dtype='float32', mode='r', shape=(2,71))\n",
    "print(fp)\n",
    "# fp[:] = np.random.randn(3,4)\n",
    "# fp[0,0] = 1.1\n",
    "# fp[0,1] = 2.2\n",
    "# fp.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# # Assuming you have two NumPy arrays of size n, array1 and array2\n",
    "# array1 = np.array([1,2,3])  # Replace with your actual array1\n",
    "# array2 = np.array([1,2,3])  # Replace with your actual array2\n",
    "\n",
    "# # Concatenate array1 and array2 to form a new array of shape (n, 2)\n",
    "# result = np.column_stack((array1, array2))\n",
    "\n",
    "# print(result)\n",
    "min(\n",
    "    10**6,\n",
    "    int(10**6 * 0.1)\n",
    "    if 10**6 >= 10**6\n",
    "    else None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38597861795300203\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "vec1= np.random.normal(size=(1000, 70))\n",
    "vec2= np.random.normal(size=(1, 70))\n",
    "# vec2_broadcasted = np.broadcast_to(vec2, vec1.shape)\n",
    "# Calculate the dot product between each vector in vec1 and the broadcasted vec2\n",
    "dot_product = np.sum(vec1 * vec2, axis=1)\n",
    "# Calculate the dot product between each vector in vec1 and vec2\n",
    "# dot_product = np.dot(vec1, vec2.T)\n",
    "\n",
    "# Calculate the norm of each vector in vec1\n",
    "norm_vec1 = np.linalg.norm(vec1, axis=1)\n",
    "\n",
    "# Calculate the norm of vec2\n",
    "norm_vec2 = np.linalg.norm(vec2)\n",
    "\n",
    "# Calculate the cosine similarity for each pair of vectors\n",
    "cosine_similarity = dot_product / (norm_vec1 * norm_vec2)\n",
    "\n",
    "cosine_similarity.squeeze()\n",
    "print(np.max(cosine_similarity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(71,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.loadtxt(\n",
    "        \"saved_db.csv\",\n",
    "        delimiter=\",\",\n",
    "        skiprows=1000,\n",
    "        dtype=np.float32,\n",
    "        usecols=range(0, 71),\n",
    "        max_rows=1\n",
    ",\n",
    "    )\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
